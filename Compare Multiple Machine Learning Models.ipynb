{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1518b3",
   "metadata": {},
   "source": [
    "# Compare Multiple Machine Learning Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d3bbea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 414 entries, 0 to 413\n",
      "Data columns (total 7 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Transaction date                     414 non-null    object \n",
      " 1   House age                            414 non-null    float64\n",
      " 2   Distance to the nearest MRT station  414 non-null    float64\n",
      " 3   Number of convenience stores         414 non-null    int64  \n",
      " 4   Latitude                             414 non-null    float64\n",
      " 5   Longitude                            414 non-null    float64\n",
      " 6   House price of unit area             414 non-null    float64\n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 22.8+ KB\n",
      "      Transaction date  House age  Distance to the nearest MRT station  \\\n",
      "0  2012-09-02 16:42:31       13.3                            4082.0150   \n",
      "1  2012-09-04 22:52:30       35.5                             274.0144   \n",
      "2  2012-09-05 01:10:52        1.1                            1978.6710   \n",
      "3  2012-09-05 13:26:01       22.2                            1055.0670   \n",
      "4  2012-09-06 08:29:48        8.5                             967.4000   \n",
      "\n",
      "   Number of convenience stores   Latitude   Longitude  \\\n",
      "0                             8  25.007059  121.561694   \n",
      "1                             2  25.012148  121.546990   \n",
      "2                            10  25.003850  121.528336   \n",
      "3                             5  24.962887  121.482178   \n",
      "4                             6  25.011037  121.479946   \n",
      "\n",
      "   House price of unit area  \n",
      "0                  6.488673  \n",
      "1                 24.970725  \n",
      "2                 26.694267  \n",
      "3                 38.091638  \n",
      "4                 21.654710  \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\USER\\Desktop\\Tedprime\\3mtt\\Real.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset and the info about the dataset\n",
    "data_head = data.head()\n",
    "data_info = data.info()\n",
    "\n",
    "print(data_head)\n",
    "print(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04106e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "''''The dataset consists of 414 entries and 7 columns, with no missing values. Here’s a brief overview of the columns:\n",
    "\n",
    "Transaction date: The date of the house sale (object type, which suggests it might need conversion or extraction of \n",
    "useful features like year, month, etc.).\n",
    "    \n",
    "House age: The age of the house in years (float).\n",
    "    \n",
    "Distance to the nearest MRT station: The distance to the nearest mass rapid transit station in meters (float).\n",
    "    \n",
    "Number of convenience stores: The number of convenience stores in the living circle on foot (integer).\n",
    "\n",
    "Latitude: The geographic coordinate that specifies the north-south position (float).\n",
    "\n",
    "Longitude: The geographic coordinate that specifies the east-west position (float).\n",
    "\n",
    "House price of unit area: Price of the house per unit area (float), which is likely our target variable for prediction.''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9d96741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "\n",
    "# convert \"Transaction date\" to datetime and extract year and month\n",
    "data['Transaction date'] = pd.to_datetime(data['Transaction date'])\n",
    "data['Transaction year'] = data['Transaction date'].dt.year\n",
    "data['Transaction month'] = data['Transaction date'].dt.month\n",
    "\n",
    "# drop the original \"Transaction date\" as we've extracted relevant features\n",
    "data = data.drop(columns=['Transaction date'])\n",
    "\n",
    "# define features and target variable\n",
    "X = data.drop('House price of unit area', axis=1)\n",
    "y = data['House price of unit area']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a5ff74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e12f9",
   "metadata": {},
   "source": [
    "# Model Training and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "''''Linear Regression: A good baseline model for regression tasks.\n",
    "Decision Tree Regressor: To see how a simple tree-based model performs.\n",
    "Random Forest Regressor: An ensemble method to improve upon the decision tree’s performance.\n",
    "Gradient Boosting Regressor: Another powerful ensemble method for regression\n",
    "\n",
    "We’ll train each model using the training data and evaluate their performance on the test set using \n",
    "Mean Absolute Error (MAE) and R-squared (R²) as metrics. These metrics will help us understand both \n",
    "the average error of the predictions and how well the model explains the variance in the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c1104e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         MAE        R²\n",
      "Linear Regression   9.748246  0.529615\n",
      "Decision Tree      11.700141  0.191559\n",
      "Random Forest       9.829512  0.513097\n",
      "Gradient Boosting  10.002797  0.475671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# initialize the models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# dictionary to hold the evaluation metrics for each model\n",
    "results = {}\n",
    "\n",
    "# train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    # training the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # making predictions on the test set\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "\n",
    "    # calculating evaluation metrics\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    # storing the metrics\n",
    "    results[name] = {\"MAE\": mae, \"R²\": r2}\n",
    "results_df = pd.DataFrame(results).T  # convert the results to a DataFrame for better readability\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''''Linear Regression has the lowest MAE (9.75) and the highest R² (0.53), making it the \n",
    "best-performing model among those evaluated. It suggests that, despite its simplicity, \n",
    "Linear Regression is quite effective for this dataset.\n",
    "\n",
    "\n",
    "Decision Tree Regressor shows the highest MAE (11.76) and the lowest R² (0.20), indicating it may be\n",
    "overfitting to the training data and performing poorly on the test data. On the other hand, Random Forest \n",
    "Regressor and Gradient Boosting Regressor have similar MAEs (9.89 and 10.00, respectively) and R² scores \n",
    "(0.51 and 0.48, respectively), performing slightly worse than the Linear Regression model but better than \n",
    "the Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefec1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
